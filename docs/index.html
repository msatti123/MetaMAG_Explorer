<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>MetaMAG Explorer: Comprehensive Metagenome-Assembled Genome Analysis Pipeline</title>
    <style>
        :root {
            --primary-color: #5e35b1;
            --secondary-color: #4fc3f7;
            --tertiary-color: #26a69a;
            --accent-color: #ff9100;
            --light-bg: #f5f5f5;
            --dark-text: #333333;
            --light-text: #ffffff;
            --border-radius: 6px;
            --box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
			--gradient: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
			--primary: #2563eb;
            --primary-dark: #1d4ed8;
            --dark: #1f2937;
            --white: #ffffff;
        }
		img {
			max-width: 100%;
			height: auto;
		}
        
        * {
            box-sizing: border-box;
            margin: 0;
            padding: 0;
        }
        
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            color: var(--dark-text);
            background-color: var(--light-bg);
            padding-bottom: 50px;
        }
        
        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 0 20px;
        }
         /* Navigation */
        nav {
            background: var(--white);
            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.05);
            position: fixed;
            width: 100%;
            top: 0;
            z-index: 1000;
        }

        .nav-container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 1rem 2rem;
            display: flex;
            justify-content: space-between;
            align-items: center;
        }

        .logo {
            font-size: 1.5rem;
            font-weight: bold;
            color: var(--primary);
            text-decoration: none;
            display: flex;
            align-items: center;
            gap: 0.5rem;
        }

        .logo svg {
            width: 32px;
            height: 32px;
        }

        .nav-links {
            display: flex;
            list-style: none;
            gap: 2rem;
            align-items: center;
        }

        .nav-links a {
            text-decoration: none;
            color: var(--dark);
            font-weight: 500;
            transition: color 0.3s ease;
        }

        .nav-links a:hover {
            color: var(--primary);
        }

        .nav-links .active {
            color: var(--primary);
            border-bottom: 2px solid var(--primary);
            padding-bottom: 2px;
        }

        .nav-cta {
            background: var(--primary);
            color: var(--white);
            padding: 0.5rem 1.25rem;
            border-radius: 6px;
            font-weight: 600;
            transition: all 0.3s ease;
        }

        .nav-cta:hover {
            background: var(--primary-dark);
            transform: translateY(-1px);
        }
		
        /* Header */
        .header {
            background: var(--gradient);
            color: var(--white);
            padding: 100px 0 40px;
            text-align: center;
        }

        .header h1 {
            font-size: 2.5rem;
            margin-bottom: 1rem;
        }

        .header p {
            font-size: 1.2rem;
            opacity: 0.9;
        }
        
        h1 {
            font-size: 2.5rem;
            margin-bottom: 15px;
        }
        
        h2 {
            font-size: 1.8rem;
            color: var(--primary-color);
            margin: 30px 0 15px;
            padding-bottom: 8px;
            border-bottom: 2px solid var(--primary-color);
        }
        
        h3 {
            font-size: 1.4rem;
            color: var(--tertiary-color);
            margin: 20px 0 10px;
        }
        
        h4 {
            font-size: 1.2rem;
            color: var(--accent-color);
            margin: 15px 0 10px;
        }
        
        p {
            margin-bottom: 15px;
        }
        
        ul, ol {
            margin-bottom: 15px;
            padding-left: 25px;
        }
        
        li {
            margin-bottom: 8px;
        }
        
        code {
            font-family: 'Courier New', Courier, monospace;
            background-color: #eee;
            padding: 2px 4px;
            border-radius: 3px;
            font-size: 0.9em;
        }
        
        pre {
            background-color: #272822;
            color: #f8f8f2;
            padding: 15px;
            border-radius: var(--border-radius);
            overflow-x: auto;
            margin-bottom: 20px;
        }
        
        pre code {
            background-color: transparent;
            color: inherit;
            padding: 0;
        }
        
        .card {
            background-color: white;
            border-radius: var(--border-radius);
            box-shadow: var(--box-shadow);
            padding: 20px;
            margin-bottom: 25px;
        }
        
        .highlight {
            background-color: rgba(94, 53, 177, 0.1);
            border-left: 4px solid var(--primary-color);
            padding: 15px;
            margin-bottom: 20px;
        }
        
        .alert {
            background-color: rgba(255, 145, 0, 0.1);
            border-left: 4px solid var(--accent-color);
            padding: 15px;
            margin-bottom: 20px;
        }
        
        .workflow-diagram {
            max-width: 100%;
            display: block;
            margin: 20px auto;
            border-radius: var(--border-radius);
            box-shadow: var(--box-shadow);
        }
        
        .parameter-table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: 20px;
        }
        
        .parameter-table th, .parameter-table td {
            padding: 10px;
            border: 1px solid #ddd;
            text-align: left;
        }
        
        .parameter-table th {
            background-color: var(--primary-color);
            color: var(--light-text);
        }
        
        .parameter-table tr:nth-child(even) {
            background-color: #f2f2f2;
        }
		/* CTA Section Styles */
		.cta-section {
			background: linear-gradient(135deg, #5e35b1, #4fc3f7);
			color: #ffffff;
			padding: 60px 20px;
			margin: 40px 0;
			text-align: center;
			border-radius: 6px;
			box-shadow: 0 10px 30px rgba(0, 0, 0, 0.1);
		}

		.cta-content {
			max-width: 800px;
			margin: 0 auto;
		}

		.cta-content h2 {
			color: #ffffff;
			font-size: 2.2rem;
			margin-bottom: 20px;
			font-weight: 700;
		}

		.cta-content p {
			font-size: 1.2rem;
			margin-bottom: 30px;
			opacity: 0.95;
			color: #ffffff;
		}

		.header-buttons {
			display: flex;
			gap: 20px;
			justify-content: center;
			flex-wrap: wrap;
			margin-top: 30px;
		}
		/* Button Styles */
		.btn {
			display: inline-flex;
			align-items: center;
			gap: 10px;
			padding: 15px 35px;
			text-decoration: none;
			border-radius: 50px;
			font-weight: 600;
			font-size: 1.1rem;
			transition: all 0.3s ease;
			box-shadow: 0 4px 15px rgba(0, 0, 0, 0.2);
		}

		.btn:hover {
			transform: translateY(-3px);
			box-shadow: 0 8px 25px rgba(0, 0, 0, 0.3);
		}

		.btn-primary {
			background-color: #ff9100;
			color: #ffffff;
		}

		.btn-primary:hover {
			background-color: #ff7043;
		}

		.btn-secondary {
			background-color: rgba(255, 255, 255, 0.2);
			color: #ffffff;
			border: 2px solid rgba(255, 255, 255, 0.5);
		}

		.btn-secondary:hover {
			background-color: rgba(255, 255, 255, 0.3);
			border-color: rgba(255, 255, 255, 0.8);
		}

		.btn-icon {
			width: 20px;
			height: 20px;
			flex-shrink: 0;
		}
        
        footer {
            text-align: center;
            margin-top: 50px;
            padding: 20px;
            color: #666;
            font-size: 0.9rem;
        }
        
        .tab-container {
            margin-bottom: 20px;
        }
        
        .tab-buttons {
            display: flex;
            flex-wrap: wrap;
            margin-bottom: 10px;
        }
        
        .tab-btn {
            background-color: #e0e0e0;
            border: none;
            padding: 10px 20px;
            margin-right: 5px;
            margin-bottom: 5px;
            cursor: pointer;
            border-radius: var(--border-radius) var(--border-radius) 0 0;
            font-weight: bold;
        }
        
        .tab-btn.active {
            background-color: var(--primary-color);
            color: var(--light-text);
        }
        
        .tab-content {
            display: none;
            padding: 20px;
            background-color: white;
            border-radius: 0 0 var(--border-radius) var(--border-radius);
            box-shadow: var(--box-shadow);
        }
        
        .tab-content.active {
            display: block;
        }
        
        .toc {
            background-color: white;
            border-radius: var(--border-radius);
            box-shadow: var(--box-shadow);
            padding: 20px;
            margin-bottom: 25px;
            position: sticky;
            top: 20px;
        }
        
        .toc h3 {
            margin-top: 0;
        }
        
        .toc ul {
            list-style-type: none;
            padding-left: 0;
        }
        
        .toc ul ul {
            padding-left: 20px;
        }
        
        .toc a {
            text-decoration: none;
            color: var(--primary-color);
        }
        
        .toc a:hover {
            text-decoration: underline;
        }
        
        .grid-container {
            display: grid;
            grid-template-columns: 1fr 3fr;
            gap: 25px;
        }
        
        @media (max-width: 768px) {
		    .cta-section {
                padding: 40px 20px;
			}
			
			.cta-content h2 {
				font-size: 1.8rem;
			}
			
			.cta-content p {
				font-size: 1rem;
			}
			
			.header-buttons {
				flex-direction: column;
				align-items: center;
			}
			
			.btn {
				width: 100%;
				max-width: 300px;
				justify-content: center;
			} 
            .grid-container {
                grid-template-columns: 1fr;
            }
            
            .toc {
                position: static;
            }
        }
    </style>
</head>
<body>
    <!-- Navigation -->
    <nav>
        <div class="nav-container">
            <a href="index.html" class="logo">
                <svg viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
                    <path d="M12 2L2 7L12 12L22 7L12 2Z" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
                    <path d="M2 17L12 22L22 17" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
                    <path d="M2 12L12 17L22 12" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
                </svg>
                MetaMAG Explorer
            </a>
            <ul class="nav-links">
                <li><a href="index.html">Home</a></li>
                <li><a href="installation.html">Installation Guide</a></li>
                <li><a href="user-guide.html" class="active">User Guide</a></li>
                <li><a href="https://github.com/msatti123/MetaMAG_Explorer">GitHub</a></li>
            </ul>
        </div>
    </nav>
	    <!-- Header -->
    <header class="header">
        <h1>MetaMAG Explorer</h1>
        <p>A Comprehensive Metagenome-Assembled Genome Analysis Pipeline</p>
    </header>
    
    <div class="container">
        <div class="grid-container">
            <div>
                <div class="toc">
                    <h3>Table of Contents</h3>
                    <ul>
                        <li><a href="#introduction">Introduction</a></li>
                        <li><a href="#pipeline-overview">Pipeline Overview</a></li>
                        <li><a href="#installation">Installation</a></li>
                        <li><a href="#usage">Usage</a>
                            <ul>
                                <li><a href="#config-file">Configuration File</a></li>
                                <li><a href="#command-line">Command Line Interface</a></li>
                                <li><a href="#running-pipeline">Running the Pipeline</a></li>
                            </ul>
                        </li>
                        <li><a href="#pipeline-steps">Pipeline Steps</a>
                            <ul>
                                <li><a href="#data-preprocessing">Data Preprocessing</a></li>
                                <li><a href="#assembly">Assembly</a></li>
                                <li><a href="#binning-refinement">Binning & Refinement</a></li>
                                <li><a href="#novel-mag-detection">Novel MAG Detection</a></li>
                                <li><a href="#functional-annotation">Functional Annotation</a></li>
                                <li><a href="#phylogeny">Phylogeny</a></li>
                                <li><a href="#abundance-estimation">Abundance Estimation</a></li>
                            </ul>
                        </li>
                        <li><a href="#special-features">Special Features</a>
                            <ul>
                                <li><a href="#rumen-mags">Rumen MAGs Processing</a></li>
                                <li><a href="#kraken-db">Kraken Database Integration</a></li>
                            </ul>
                        </li>
                        <li><a href="#output-files">Output Files</a></li>
                        <li><a href="#faq">FAQ</a></li>
                        <li><a href="#troubleshooting">Troubleshooting</a></li>
                        <li><a href="#references">References</a></li>
                    </ul>
                </div>
            </div>
            
            <div>
                <section id="introduction" class="card">
                    <h2>Introduction</h2>
                    <p>MetaMAG Explorer is a comprehensive pipeline designed for the identification, processing, and analysis of Metagenome-Assembled Genomes (MAGs) from metagenomic data. This pipeline excels in detecting novel MAGs and integrating them into reference databases, with specialized handling for rumen microbiome data.</p>
                    
                    <p>The pipeline incorporates state-of-the-art tools for quality control, assembly, binning, and functional annotation, providing a complete solution for metagenomic analysis from raw reads to functionally annotated genomes and phylogenetic placement.</p>
                    
                    <div class="highlight">
                        <h4>Key Features:</h4>
                        <ul>
                            <li><strong>Comprehensive Processing:</strong> End-to-end workflow from raw reads to functionally annotated MAGs</li>
                            <li><strong>Novel MAG Detection:</strong> Specialized modules for identifying and processing novel genomes</li>
                            <li><strong>Rumen Data Support:</strong> Special handling for rumen microbiome data with reference MAG integration</li>
                            <li><strong>Database Integration:</strong> Automatic integration of novel MAGs into Kraken2 databases for future analyses</li>
                            <li><strong>High Performance:</strong> Optimized for HPC environments with SLURM integration</li>
                            <li><strong>Modular Design:</strong> Run specific steps independently or the entire pipeline</li>
                        </ul>
                    </div>
                </section>
                
                <section id="pipeline-overview" class="card">
                    <h2>Pipeline Overview</h2>
                    <p>MetaMAG Explorer is organized into several major modules that can be run sequentially or independently:</p>
                    
                    <img src="images/MetaMAG_Flow.png">
                    
                    <p>The pipeline consists of these main components:</p>
                    
                    <ol>
                        <li><strong>Data Preprocessing:</strong> Quality control, trimming, and host removal</li>
                        <li><strong>Assembly:</strong> Single-sample and co-assembly of metagenomic reads</li>
                        <li><strong>Binning & Refinement:</strong> MAG binning, refinement, dereplication, and evaluation</li>
                        <li><strong>Novel MAG Detection:</strong> Identification and processing of novel MAGs</li>
                        <li><strong>Functional Annotation:</strong> Annotation of MAGs with eggNOG, KEGG, and dbCAN</li>
                        <li><strong>Phylogeny:</strong> Construction and visualization of phylogenetic trees</li>
                        <li><strong>Abundance Estimation:</strong> Quantification of MAG abundance across samples</li>
                    </ol>
                    
                    <h3>Novel MAG Detection & Database Augmentation</h3>
                    <p>A unique feature of this pipeline is its comprehensive novel MAG detection and database integration module:</p>
                    
                    <img src="images/MetaMAG_DB_Flow.png">
                    <p>This specialized workflow identifies novel MAGs, dereplicates them against existing repositories, and integrates them into reference databases for improved future analyses.</p>
                </section>
                
                
                <section id="pipeline-steps" class="card">
                    <h2>Pipeline Steps in Detail</h2>
                    
                    <h3 id="data-preprocessing">Data Preprocessing</h3>
                    <h4>Quality Control</h4>
                    <p>The pipeline begins with quality assessment of raw sequencing reads using FastQC, which generates comprehensive reports on sequence quality, adapter content, and other metrics.</p>
                    
                    <h4>Trimming</h4>
                    <p>Low-quality bases and adapter sequences are removed using Fastp. This step improves assembly quality by removing error-prone regions of reads.</p>
                    
                    <h4>Host Removal</h4>
                    <p>For metagenomes from host-associated environments (e.g., rumen, human gut), the pipeline maps reads against host reference genomes using BWA-mem and removes host-derived sequences. This step is crucial for accurate microbial genome assembly.</p>
                    
                    <h3 id="assembly">Assembly</h3>
                    <h4>Single Sample Assembly</h4>
                    <p>Individual samples are assembled using IDBA-UD, an iterative De Bruijn graph assembler optimized for uneven-depth metagenomic data. This approach works well for capturing dominant genomes in individual samples.</p>
                    
                    <h4>Co-Assembly</h4>
                    <p>Reads from multiple samples are combined and assembled using MEGAHIT, which is memory-efficient and can handle large datasets. Co-assembly improves recovery of low-abundance genomes that may be present across multiple samples.</p>
                    
                    <h4>Assembly Evaluation</h4>
                    <p>MetaQUAST is used to evaluate assembly quality metrics such as N50, total assembly length, and contig length distribution.</p>
                    
                    <h3 id="binning-refinement">Binning & Refinement</h3>
                    <h4>Binning</h4>
                    <p>The pipeline employs multiple binning algorithms to group contigs into putative genomes:</p>
                    <ul>
                        <li><strong>MetaBAT2:</strong> Uses tetranucleotide frequencies and coverage information</li>
                        <li><strong>MaxBin2:</strong> Expectation-maximization algorithm for binning</li>
                        <li><strong>CONCOCT:</strong> Uses sequence composition and coverage across samples</li>
                    </ul>
                    
                    <h4>Bin Refinement</h4>
                    <p>Results from different binning tools are integrated using DAS Tool, which selects the optimal bins from each binning approach to create a non-redundant set of high-quality MAGs.</p>
                    
                    <h4>Dereplication</h4>
                    <p>dRep is used to identify and remove redundant MAGs based on genome similarity, ensuring a non-redundant set of genomes for downstream analysis.</p>
                    
                    <h4>Evaluation</h4>
                    <p>CheckM2 assesses MAG quality by estimating completeness and contamination based on single-copy marker genes. This quality assessment is crucial for identifying high-quality MAGs for further analysis.</p>
                    
                    <h3 id="novel-mag-detection">Novel MAG Detection & Processing</h3>
                    <h4>GTDB-Tk Classification</h4>
                    <p>GTDB-Tk assigns taxonomy to MAGs based on the Genome Taxonomy Database. This step is critical for identifying potentially novel genomes that lack species-level assignments.</p>
                    
                    <h4>Novel MAG Identification</h4>
                    <p>MAGs with missing species-level assignments in GTDB-Tk results are identified as potentially novel. The pipeline extracts these candidates for further processing.</p>
                    
                    <h4>Dereplication Against MAG Repository</h4>
                    <p>Novel MAG candidates are dereplicated against a repository of previously identified MAGs to ensure they represent truly unique genomes not already present in the database.</p>
                    
                    <h4>Rumen-Specific Processing</h4>
                    <p>For rumen data, additional dereplication is performed against dedicated rumen reference MAGs. This ensures that MAGs unique to the rumen microbiome are properly identified and processed.</p>
                    
                    <h4>MAG Repository Update</h4>
                    <p>Verified novel MAGs are added to a central MAG repository for future reference and dereplication.</p>
                    
                    <h4>Kraken Database Integration</h4>
                    <p>The pipeline integrates novel MAGs into a Kraken2 database for improved metagenomic classification in future analyses. This step includes:</p>
                    <ul>
                        <li>Assigning placeholder taxonomy to MAGs with incomplete classifications</li>
                        <li>Converting GTDB taxonomy to NCBI taxdump format</li>
                        <li>Reformatting sequence headers for Kraken2 compatibility</li>
                        <li>Building the Kraken2 database</li>
                    </ul>
                    
                    <h3 id="functional-annotation">Functional Annotation</h3>
                    <h4>eggNOG Annotation</h4>
                    <p>MAGs are functionally annotated using eggNOG-mapper, which assigns orthology groups, KEGG orthology (KO) terms, and Gene Ontology (GO) terms to predicted genes.</p>
                    
                    <h4>CAZyme Annotation</h4>
                    <p>The dbCAN tool is used to identify Carbohydrate-Active Enzymes (CAZymes) in MAGs, which are particularly important for understanding polysaccharide metabolism in the rumen microbiome.</p>
                    
                    <h4>Functional Analysis</h4>
                    <p>KEGG annotations are analyzed to identify key metabolic pathways and functions present in the MAGs, providing insights into their ecological roles.</p>
                    
                    <h3 id="phylogeny">Phylogeny</h3>
                    <h4>Phylogenetic Tree Construction</h4>
                    <p>Phylogenetic trees are constructed based on marker genes to establish evolutionary relationships among the MAGs and reference genomes.</p>
                    
                    <h4>Tree Visualization</h4>
                    <p>Trees are visualized with taxonomic and functional annotations to facilitate interpretation of evolutionary relationships and functional traits.</p>
                    
                    <h3 id="abundance-estimation">Abundance Estimation</h3>
                    <h4>Kraken2-Based Quantification</h4>
                    <p>The updated Kraken2 database, which includes novel MAGs, is used to estimate the abundance of MAGs across samples, providing insights into community composition and dynamics.</p>
                </section>
                
                <section id="special-features" class="card">
                    <h2>Special Features</h2>
                    
                    <h3 id="rumen-mags">Rumen MAGs Processing</h3>
                    <p>The pipeline includes specialized handling for rumen microbiome data:</p>
                    
                    <div class="highlight">
                        <h4>Rumen-Specific Workflow:</h4>
                        <ol>
                            <li><strong>Reference MAG Download:</strong> Automatically downloads reference MAGs from key rumen microbiome projects (RUG, RMGMC, MGnify)</li>
                            <li><strong>Rumen MAG Dereplication:</strong> Dereplicates rumen-specific MAGs to create a non-redundant reference set</li>
                            <li><strong>Rumen-Specific Novel MAG Detection:</strong> Identifies MAGs that are novel compared to existing rumen reference genomes</li>
                            <li><strong>Rumen Reference Integration:</strong> Updates rumen reference MAG collections with newly identified genomes</li>
                        </ol>
                    </div>
                    
                    <p>This specialized handling improves the characterization of the rumen microbiome, which is crucial for understanding feed efficiency, methane emissions, and overall cattle health.</p>
                    
                    <h3 id="kraken-db">Kraken Database Integration</h3>
                    <p>The pipeline's Kraken database integration module enables continuous improvement of metagenomic classification:</p>
                    
                    <div class="highlight">
                        <h4>Key Features:</h4>
                        <ul>
                            <li><strong>Automatic Taxonomy Assignment:</strong> Uses GTDB-Tk results and implements placeholder taxonomy for incomplete classifications</li>
                            <li><strong>Taxonomy Format Conversion:</strong> Converts GTDB taxonomy to NCBI taxdump format required by Kraken2</li>
                            <li><strong>Header Formatting:</strong> Ensures sequence headers contain taxonomy IDs in Kraken2-compatible format</li>
                            <li><strong>Database Building:</strong> Automates the process of adding sequences to the Kraken2 library and building the database</li>
                        </ul>
                    </div>
                    
                    <p>This integration enables improved classification of metagenomic sequences in future analyses by incorporating project-specific novel genomes into the reference database.</p>
                </section>
                
                <section id="output-files" class="card">
                    <h2>Output Files</h2>
                    <p>The pipeline generates a structured output directory containing the following key files and directories:</p>
                    
                    <pre><code>output_dir/
+-- QC/                         # Quality control reports
+-- Trimming/                   # Trimmed read files
+-- Host_Removal/               # Host-filtered read files
+-- Assembly/
¦   +-- IDBA/                   # Single-sample assemblies
¦   +-- MEGAHIT/                # Co-assemblies
+-- MetaQUAST/                  # Assembly quality evaluation
+-- Binning/                    # Raw binning results
+-- Bin_Refinement/             # Refined bins
¦   +-- drep/                   # Dereplicated MAGs
+-- Evaluation/                 # CheckM2 quality assessment
+-- Novel_Mags/
¦   +-- gtdbtk/                 # GTDB-Tk classification results
¦   +-- UniqueMags/             # Candidate novel MAGs
¦   +-- filtered_NMAGs/         # MAGs after repository dereplication
¦   +-- true_novel_MAGs/        # Final set of novel MAGs
+-- MAGs_Repository/            # Central repository of all MAGs
+-- Kraken_Database/            # Kraken2 database with novel MAGs
+-- Functional_Annotation/
¦   +-- eggNOG/                 # eggNOG annotation results
¦   +-- dbCAN/                  # CAZyme annotations
¦   +-- KEGG/                   # KEGG functional analysis
+-- Phylogeny/                  # Phylogenetic trees
+-- Abundance/                  # MAG abundance estimates</code></pre>
                </section>
                <div class="cta-section">
                    <div class="cta-content">
                        <h2>Start Using the MetaMAG Pipeline</h2>
                        <p>Follow the installation steps and run the pipeline to process your metagenomic data from raw reads to annotated genomes. You can run all steps or just the parts you need.</p>
                        <div class="header-buttons">
                            <a href="installation.html" class="btn btn-primary">
                                <svg class="btn-icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                    <path d="M21 15v4a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2v-4M7 10l5 5 5-5M12 15V3"/>
                                </svg>
                                Install Now
                            </a>
                            <a href="user-guide.html" class="btn btn-secondary">
                                <svg class="btn-icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                    <path d="M9 12h6M9 16h6M17 21H7a2 2 0 0 1-2-2V5a2 2 0 0 1 2-2h10a2 2 0 0 1 2 2v14a2 2 0 0 1-2 2z"/>
                                </svg>
                                Read Documentation
                            </a>
                        </div>
                    </div>
                </div>

                <section id="faq" class="card">
                    <h2>Frequently Asked Questions</h2>
                    
                    <div class="tab-container">
                        <div class="tab-buttons">
                            <button class="tab-btn active" onclick="openTab(event, 'general-faq')">General</button>
                            <button class="tab-btn" onclick="openTab(event, 'rumen-faq')">Rumen Data</button>
                            <button class="tab-btn" onclick="openTab(event, 'performance-faq')">Performance</button>
                        </div>
                        
                        <div id="general-faq" class="tab-content active">
                            <h4>Q: What types of metagenomic data can be processed with this pipeline?</h4>
                            <p>A: MetaMAG Explorer can process shotgun metagenomic data from any environment, with specialized features for host-associated microbiomes, particularly the rumen microbiome.</p>
                            
                            <h4>Q: Can I use long-read sequencing data (PacBio/Nanopore)?</h4>
                            <p>A: The current pipeline is designed for short-read Illumina data. Long reads would require different assemblers (like metaFlye or Canu) and modified quality control steps.</p>
                            
                            <h4>Q: How does the pipeline define "novel" MAGs?</h4>
                            <p>A: MAGs are considered potentially novel if they lack a species-level classification in GTDB-Tk results (indicated by "s__" in the taxonomy string). They are confirmed as novel if they pass dereplication against existing MAG repositories.</p>
                        </div>
                        
                        <div id="rumen-faq" class="tab-content">
                            <h4>Q: What reference MAG collections are used for rumen data?</h4>
                            <p>A: The pipeline can incorporate MAGs from major rumen microbiome projects including RUG (Rumen Uncultured Genomes), RMGMC (Rumen Microbial Genomics Multi-Country), and MGnify rumen MAGs.</p>
                            
                            <h4>Q: How does rumen-specific processing differ from standard processing?</h4>
                            <p>A: Rumen-specific processing includes additional dereplication against established rumen reference MAGs and maintains a separate collection of rumen-specific novel MAGs for future reference.</p>
                            
                            <h4>Q: Can I use the pipeline for other host-associated microbiomes?</h4>
                            <p>A: Yes, the pipeline can be adapted for other host-associated microbiomes by providing the appropriate host reference genome for host removal and reference MAG collections for dereplication.</p>
                        </div>
                        
                        <div id="performance-faq" class="tab-content">
                            <h4>Q: What computational resources are required?</h4>
                            <p>A: Resource requirements vary by step and dataset size. As a general guideline:
                                <ul>
                                    <li>Assembly: 100-200 GB RAM for co-assembly of multiple samples</li>
                                    <li>Binning: 32-64 GB RAM</li>
                                    <li>GTDB-Tk: 100-200 GB RAM</li>
                                    <li>Storage: 1-5 TB for a typical project with 20-50 samples</li>
                                </ul>
                            </p>
                            
                            <h4>Q: How can I speed up the pipeline?</h4>
                            <p>A: Running steps in parallel, using more CPU cores, and allocating sufficient memory will reduce runtime.</p>
							<h4>Q: Can I adjust resources for individual steps?</h4>
                            <p>A: Yes, resource requirements (CPU, memory, time) can be customized per step in the configuration file or SLURM job submission script.</p>
							<h4>Q: Can failed jobs be restarted without repeating everything?</h4>
                            <p>A:Yes, the pipeline supports checkpointing and modular execution, so failed steps can be rerun independently.</p>
							<h4>Q: Does running on multiple nodes improve performance?</h4>
                            <p>A:Yes, the pipeline is designed for HPC environments and can distribute tasks across multiple nodes for efficiency.</p>
                               
                            
                        </div>
                    </div>
                </section>
                
                <section id="troubleshooting" class="card">
                    <h2>Troubleshooting</h2>
                    
                    <div class="alert">
                        <h4>Common Issues and Solutions</h4>
                        
                        <h4>SLURM Job Failures</h4>
                        <p><strong>Issue:</strong> Jobs fail with out-of-memory errors.</p>
                        <p><strong>Solution:</strong> Increase the memory allocation in the <code>--memory</code> parameter or reduce the batch size.</p>
                        
                        <h4>GTDB-Tk Classification Errors</h4>
                        <p><strong>Issue:</strong> GTDB-Tk fails with database-related errors.</p>
                        <p><strong>Solution:</strong> Ensure the GTDB-Tk database is properly installed and the environment variable GTDBTK_DATA_PATH is set correctly.</p>
                        
                        <h4>dRep Failures</h4>
                        <p><strong>Issue:</strong> dRep fails during genome comparison.</p>
                        <p><strong>Solution:</strong> Check if input MAGs meet minimum quality requirements (completeness > 50%, contamination < 10%). Increase memory allocation for dRep.</p>
                        
                        <h4>Kraken Database Build Failures</h4>
                        <p><strong>Issue:</strong> Kraken database building fails.</p>
                        <p><strong>Solution:</strong> Ensure sufficient disk space for the database. Check if the taxonomy files (nodes.dmp, names.dmp) are properly formatted.</p>
                    </div>
                    
                    <p>For additional troubleshooting and support, please open an issue in the GitHub repository or contact the developers directly.</p>
                </section>
				
				
				
                
                <section id="references" class="card">
                   
                    
                     <h2>Complete List of Tools and Software Used</h2>
    
    <h3>Quality Control & Preprocessing</h3>
    <ul>
        <li><strong>FastQC:</strong> Andrews, S. (2010). <em>FastQC: A quality control tool for high throughput sequence data.</em> Babraham Bioinformatics. Available at: <a href="https://www.bioinformatics.babraham.ac.uk/projects/fastqc/">https://www.bioinformatics.babraham.ac.uk/projects/fastqc/</a></li>
        
        <li><strong>fastp:</strong> Chen, S., Zhou, Y., Chen, Y., & Gu, J. (2018). fastp: an ultra-fast all-in-one FASTQ preprocessor. <em>Bioinformatics</em>, 34(17), i884-i890. <a href="https://doi.org/10.1093/bioinformatics/bty560">https://doi.org/10.1093/bioinformatics/bty560</a></li>
        
        <li><strong>BWA-MEM:</strong> Li, H. (2013). Aligning sequence reads, clone sequences and assembly contigs with BWA-MEM. <em>arXiv preprint</em>, arXiv:1303.3997.</li>
        
        <li><strong>SAMtools:</strong> Li, H., Handsaker, B., Wysoker, A., et al. (2009). The Sequence Alignment/Map format and SAMtools. <em>Bioinformatics</em>, 25(16), 2078-2079. <a href="https://doi.org/10.1093/bioinformatics/btp352">https://doi.org/10.1093/bioinformatics/btp352</a></li>
    </ul>
    
    <h3>Assembly Tools</h3>
    <ul>
        <li><strong>IDBA-UD:</strong> Peng, Y., Leung, H. C. M., Yiu, S. M., & Chin, F. Y. L. (2012). IDBA-UD: a de novo assembler for single-cell and metagenomic sequencing data with highly uneven depth. <em>Bioinformatics</em>, 28(11), 1420-1428. <a href="https://doi.org/10.1093/bioinformatics/bts174">https://doi.org/10.1093/bioinformatics/bts174</a></li>
        
        <li><strong>MEGAHIT:</strong> Li, D., Liu, C. M., Luo, R., Sadakane, K., & Lam, T. W. (2015). MEGAHIT: an ultra-fast single-node solution for large and complex metagenomics assembly via succinct de Bruijn graph. <em>Bioinformatics</em>, 31(10), 1674-1676. <a href="https://doi.org/10.1093/bioinformatics/btv033">https://doi.org/10.1093/bioinformatics/btv033</a></li>
        
        <li><strong>MetaQUAST:</strong> Mikheenko, A., Saveliev, V., & Gurevich, A. (2016). MetaQUAST: evaluation of metagenome assemblies. <em>Bioinformatics</em>, 32(7), 1088-1090. <a href="https://doi.org/10.1093/bioinformatics/btv697">https://doi.org/10.1093/bioinformatics/btv697</a></li>
    </ul>
    
    <h3>Binning & Refinement</h3>
    <ul>
        <li><strong>MetaWRAP:</strong> Uritskiy, G. V., DiRuggiero, J., & Taylor, J. (2018). MetaWRAP-a flexible pipeline for genome-resolved metagenomic data analysis. <em>Microbiome</em>, 6, 158. <a href="https://doi.org/10.1186/s40168-018-0541-1">https://doi.org/10.1186/s40168-018-0541-1</a></li>
        
        <li><strong>MetaBAT2:</strong> Kang, D. D., Li, F., Kirton, E., et al. (2019). MetaBAT 2: an adaptive binning algorithm for robust and efficient genome reconstruction from metagenome assemblies. <em>PeerJ</em>, 7, e7359. <a href="https://doi.org/10.7717/peerj.7359">https://doi.org/10.7717/peerj.7359</a></li>
        
        <li><strong>MaxBin2:</strong> Wu, Y. W., Simmons, B. A., & Singer, S. W. (2016). MaxBin 2.0: an automated binning algorithm to recover genomes from multiple metagenomic datasets. <em>Bioinformatics</em>, 32(4), 605-607. <a href="https://doi.org/10.1093/bioinformatics/btv638">https://doi.org/10.1093/bioinformatics/btv638</a></li>
        
        <li><strong>CONCOCT:</strong> Alneberg, J., Bjarnason, B. S., de Bruijn, I., et al. (2014). Binning metagenomic contigs by coverage and composition. <em>Nature Methods</em>, 11, 1144-1146. <a href="https://doi.org/10.1038/nmeth.3103">https://doi.org/10.1038/nmeth.3103</a></li>
        
        <li><strong>DAS Tool:</strong> Sieber, C. M. K., Probst, A. J., Sharrar, A., et al. (2018). Recovery of genomes from metagenomes via a dereplication, aggregation and scoring strategy. <em>Nature Microbiology</em>, 3, 836-843. <a href="https://doi.org/10.1038/s41564-018-0171-1">https://doi.org/10.1038/s41564-018-0171-1</a></li>
    </ul>
    
    <h3>Quality Assessment & Dereplication</h3>
    <ul>
        <li><strong>dRep:</strong> Olm, M. R., Brown, C. T., Brooks, B., & Banfield, J. F. (2017). dRep: a tool for fast and accurate genomic comparisons that enables improved genome recovery from metagenomes through de-replication. <em>ISME Journal</em>, 11, 2864-2868. <a href="https://doi.org/10.1038/ismej.2017.126">https://doi.org/10.1038/ismej.2017.126</a></li>
        
        <li><strong>CheckM2:</strong> Chklovski, A., Parks, D. H., Woodcroft, B. J., Tyson, G. W., & Hugenholtz, P. (2023). CheckM2: assessing quality of metagenome-assembled genomes using machine learning. <em>Nature Biotechnology</em>. <a href="https://doi.org/10.1038/s41587-023-01782-8">https://doi.org/10.1038/s41587-023-01782-8</a></li>
        
        <li><strong>fastANI:</strong> Jain, C., Rodriguez-R, L. M., Phillippy, A. M., Konstantinidis, K. T., & Aluru, S. (2018). High throughput ANI analysis of 90K prokaryotic genomes reveals clear species boundaries. <em>Nature Communications</em>, 9, 5114. <a href="https://doi.org/10.1038/s41467-018-07641-9">https://doi.org/10.1038/s41467-018-07641-9</a></li>
    </ul>
    
    <h3>Taxonomic Classification</h3>
    <ul>
        <li><strong>GTDB-Tk:</strong> Chaumeil, P. A., Parks, D. H., Rinke, C., & Hugenholtz, P. (2019). GTDB-Tk: A toolkit to classify genomes with the Genome Taxonomy Database. <em>Bioinformatics</em>, 36(6), 1925-1927. <a href="https://doi.org/10.1093/bioinformatics/btz848">https://doi.org/10.1093/bioinformatics/btz848</a></li>
        
        <li><strong>Kraken2:</strong> Wood, D. E., Lu, J., & Langmead, B. (2019). Improved metagenomic analysis with Kraken 2. <em>Genome Biology</em>, 20, 257. <a href="https://doi.org/10.1186/s13059-019-1891-0">https://doi.org/10.1186/s13059-019-1891-0</a></li>
        
        <li><strong>Bracken:</strong> Lu, J., Breitwieser, F. P., Thielen, P., & Salzberg, S. L. (2017). Bracken: estimating species abundance in metagenomic data. <em>PeerJ Computer Science</em>, 3, e104. <a href="https://doi.org/10.7717/peerj-cs.104">https://doi.org/10.7717/peerj-cs.104</a></li>
    </ul>
    
    <h3>Functional Annotation</h3>
    <ul>
        <li><strong>Prodigal:</strong> Hyatt, D., Chen, G. L., LoCascio, P. F., Land, M. L., Larimer, F. W., & Hauser, L. J. (2010). Prodigal: prokaryotic gene recognition and translation initiation site identification. <em>BMC Bioinformatics</em>, 11, 119. <a href="https://doi.org/10.1186/1471-2105-11-119">https://doi.org/10.1186/1471-2105-11-119</a></li>
        
        <li><strong>eggNOG-mapper:</strong> Cantalapiedra, C. P., Hernandez-Plaza, A., Letunic, I., Bork, P., & Huerta-Cepas, J. (2021). eggNOG-mapper v2: Functional annotation, orthology assignments, and domain prediction at the metagenomic scale. <em>Molecular Biology and Evolution</em>, 38(12), 5825-5829. <a href="https://doi.org/10.1093/molbev/msab293">https://doi.org/10.1093/molbev/msab293</a></li>
        
        <li><strong>dbCAN3:</strong> Zheng, J., Ge, Q., Yan, Y., Zhang, X., Huang, L., & Yin, Y. (2023). dbCAN3: automated carbohydrate-active enzyme and substrate annotation. <em>Nucleic Acids Research</em>, 51(W1), W115-W121. <a href="https://doi.org/10.1093/nar/gkad328">https://doi.org/10.1093/nar/gkad328</a></li>
        
        <li><strong>HMMER:</strong> Used with dbCAN for HMM-based searches (integrated within dbCAN3)</li>
        
        <li><strong>DIAMOND:</strong> Used with eggNOG-mapper and dbCAN for fast sequence alignment</li>
    </ul>
    
    <h3>Visualization & Analysis</h3>
    <ul>
        <li><strong>matplotlib:</strong> Hunter, J. D. (2007). Matplotlib: A 2D graphics environment. <em>Computing in Science & Engineering</em>, 9(3), 90-95. <a href="https://doi.org/10.1109/MCSE.2007.55">https://doi.org/10.1109/MCSE.2007.55</a></li>
        
        <li><strong>seaborn:</strong> Waskom, M. L. (2021). seaborn: statistical data visualization. <em>Journal of Open Source Software</em>, 6(60), 3021. <a href="https://doi.org/10.21105/joss.03021">https://doi.org/10.21105/joss.03021</a></li>
        
        <li><strong>plotly:</strong> Plotly Technologies Inc. (2015). <em>Collaborative data science</em>. Montreal, QC. Available at: <a href="https://plot.ly">https://plot.ly</a></li>
        
        <li><strong>NetworkX:</strong> Hagberg, A. A., Schult, D. A., & Swart, P. J. (2008). Exploring network structure, dynamics, and function using NetworkX. In <em>Proceedings of the 7th Python in Science Conference (SciPy 2008)</em>, 11-15.</li>
        
        <li><strong>ape (R):</strong> Paradis, E., Claude, J., & Strimmer, K. (2004). APE: Analyses of Phylogenetics and Evolution in R language. <em>Bioinformatics</em>, 20(2), 289-290. <a href="https://doi.org/10.1093/bioinformatics/btg412">https://doi.org/10.1093/bioinformatics/btg412</a></li>
        
        <li><strong>RColorBrewer (R):</strong> Neuwirth, E. (2022). RColorBrewer: ColorBrewer Palettes. R package version 1.1-3. Available at: <a href="https://cran.r-project.org/package=RColorBrewer">https://cran.r-project.org/package=RColorBrewer</a></li>
        
        <li><strong>ggtree (R):</strong> Yu, G., Smith, D. K., Zhu, H., Guan, Y., & Lam, T. T.-Y. (2017). ggtree: an R package for visualization and annotation of phylogenetic trees with their covariates and other associated data. <em>Methods in Ecology and Evolution</em>, 8(1), 28-36. <a href="https://doi.org/10.1111/2041-210X.12628">https://doi.org/10.1111/2041-210X.12628</a></li>
        
        <li><strong>ggplot2 (R):</strong> Wickham H. (2016). <em>ggplot2: Elegant Graphics for Data Analysis</em>. Springer-Verlag New York. ISBN 978-3-319-24277-4, <a href="https://ggplot2.tidyverse.org">https://ggplot2.tidyverse.org</a></li>
    </ul>
    
    <h3>Data Retrieval</h3>
    <ul>
        <li><strong>SRA Toolkit:</strong> Leinonen, R., Sugawara, H., Shumway, M., & International Nucleotide Sequence Database Collaboration. (2011). The Sequence Read Archive. <em>Nucleic Acids Research</em>, 39(Database issue), D19-D21. <a href="https://doi.org/10.1093/nar/gkq1019">https://doi.org/10.1093/nar/gkq1019</a></li>
    </ul>
    
    <h3>Other Mentioned Pipelines (for comparison)</h3>
    <ul>
        <li><strong>SqueezeMeta:</strong> Tamames, J. & Puente-Sanchez, F. (2019). SqueezeMeta, a highly portable, fully automatic metagenomic analysis pipeline from reads to bins. <em>Frontiers in Microbiology</em>, 9, 3349. <a href="https://doi.org/10.3389/fmicb.2018.03349">https://doi.org/10.3389/fmicb.2018.03349</a></li>
        
        <li><strong>ATLAS:</strong> Kieser, S., Brown, J., Zdobnov, E. M., Trajkovski, M., & McCue, L. A. (2020). ATLAS: a Snakemake workflow for assembly, annotation, and genomic binning of metagenome sequence data. <em>BMC Bioinformatics</em>, 21, 257. <a href="https://doi.org/10.1186/s12859-020-03585-4">https://doi.org/10.1186/s12859-020-03585-4</a></li>
        
        <li><strong>METABOLIC:</strong> Zhou, Z., Tran, P. Q., Breister, A. M., et al. (2022). METABOLIC: high-throughput profiling of microbial genomes for functional traits, metabolism, biogeochemistry, and community-scale functional networks. <em>Microbiome</em>, 10, 33. <a href="https://doi.org/10.1186/s40168-021-01213-8">https://doi.org/10.1186/s40168-021-01213-8</a></li>
        
        <li><strong>EasyMetagenome:</strong> Bai, D., et al. (2025). EasyMetagenome: A user-friendly and flexible pipeline for shotgun metagenomic analysis in microbiome research. <em>iMeta</em>, 4(1), e70001. <a href="https://doi.org/10.1002/imt2.70001">https://doi.org/10.1002/imt2.70001</a></li>
    </ul>
                </section>
            </div>
        </div>
    </div>
    
    <footer>
        <p>MetaMAG Explorer &copy; 2025 | Documentation Generated: May 10, 2025</p>
    </footer>
    
    <script>
        function openTab(evt, tabName) {
            var i, tabcontent, tabbuttons;
            
            tabcontent = document.getElementsByClassName("tab-content");
            for (i = 0; i < tabcontent.length; i++) {
                tabcontent[i].className = tabcontent[i].className.replace(" active", "");
            }
            
            tabbuttons = document.getElementsByClassName("tab-btn");
            for (i = 0; i < tabbuttons.length; i++) {
                tabbuttons[i].className = tabbuttons[i].className.replace(" active", "");
            }
            
            document.getElementById(tabName).className += " active";
            evt.currentTarget.className += " active";
        }
    </script>
</body>
</html>
